# -*- coding: utf-8 -*-
# @Author: Haiqin Yang
# @Date:   2025-09-16 17:41:32
# @Last Modified by:   Haiqin Yang
# @Last Modified time: 2025-09-16 20:37:32

# æ„å»ºåŸºäºè§„åˆ™çš„æƒ…æ„Ÿåˆ†ç±»å™¨

è¿™æ˜¯[æ·±åœ³æŠ€æœ¯å¤§å­¦2025ç§‹å­£å¾®ä¸“ä¸šè¯¾](https://hqyang.github.io/nlp-fall25/)ä½¿ç”¨çš„Jupyter Notebook.ä¸‹é¢å°è¯•æ„å»ºåŸºä¸€ä¸ªåŸºäºè§„åˆ™çš„æƒ…æ„Ÿåˆ†ç±»å™¨ã€‚å®ƒå°†æ¥æ”¶æ–‡æœ¬â€œXâ€å¹¶è¿”å›ä¸€ä¸ªâ€œæ ‡ç­¾â€ï¼Œå¦‚æœæ–‡æœ¬çš„æƒ…æ„Ÿæ˜¯ç§¯æçš„ï¼Œåˆ™ä¸ºâ€œ1â€ï¼Œå¦‚æœæ–‡æœ¬çš„æƒ…æ„Ÿæ˜¯æ¶ˆæçš„ï¼Œåˆ™ä¸ºâ€œ-1â€ï¼Œå¦‚æœæ–‡æœ¬çš„æƒ…æ„Ÿæ˜¯ä¸­æ€§çš„ï¼Œåˆ™ä¸ºâ€œ0â€ã€‚é€šè¿‡è¿è¡Œè¿™ä¸ªnotebook ä½ å¯ä»¥åœ¨[Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/index.html)ä¸Šæµ‹è¯•åˆ†ç±»å™¨çš„å‡†ç¡®æ€§ã€‚

Notebookå”¯ä¸€éœ€è¦æ›´æ”¹çš„æ˜¯ä»¥ä¸‹ä¸¤ä¸ªå•å…ƒæ ¼:
1. `extract_features(X)`: å®ƒå°†ä»æ–‡æœ¬ä¸­æå–ï¼ˆå‘½åçš„ï¼‰ç‰¹å¾å€¼çš„å­—å…¸ã€‚æ‚¨åº”è¯¥è‡ªå·±æ‰‹åŠ¨åˆ›å»ºå­—å…¸ï¼Œä¸‹é¢å°†ä¸ºæ‚¨å±•ç¤ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ã€‚
2. `feature_weights`: è¿™æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå®ƒå°†ä¸ºæ¯ä¸ªæå–çš„ç‰¹å¾åˆ†é…ä¸€ä¸ªæƒé‡ã€‚

åˆ†ç±»å™¨å†³å®šæ˜¯å¦åˆ†é…ç§¯æã€æ¶ˆææˆ–ä¸­æ€§æ ‡ç­¾çš„æœ€ç»ˆæ–¹æ³•æ˜¯é€šè¿‡è®¡ç®—ç‚¹ç§¯`feature_weights * extract_features(X)`ï¼Œå¦‚æœå€¼å¤§äºé›¶ï¼Œè¿”å›1ï¼Œå°äºé›¶è¿”å›-1ï¼Œå¦‚æœæ­£å¥½ä¸ºé›¶è¿”å›0ã€‚

è®©æˆ‘ä»¬æ¥å°è¯•è®¾è®¡ä¸€ä¸ªåˆ†ç±»å™¨ ğŸ˜
"""

def extract_features(x: str) -> dict[str, float]:
    features = {}
    x_split = x.split(' ')

    # Count the number of "good words" and "bad words" in the text
    good_words = ['love', 'good', 'nice', 'great', 'enjoy', 'enjoyed']
    bad_words = ['hate', 'bad', 'terrible', 'disappointing', 'sad', 'lost', 'angry']
    for x_word in x_split:
        if x_word in good_words:
            features['good_word_count'] = features.get('good_word_count', 0) + 1
        if x_word in bad_words:
            features['bad_word_count'] = features.get('bad_word_count', 0) + 1

    # The "bias" value is always one, to allow us to assign a "default" score to the text
    features['bias'] = 1

    return features

feature_weights = {'good_word_count': 1.0, 'bad_word_count': -1.0, 'bias': 0.5}

"""## Data Reading

Read in the data from the training and dev (or finally test) sets
"""

def read_xy_data(filename: str) -> tuple[list[str], list[int]]:
    x_data = []
    y_data = []
    with open(filename, 'r') as f:
        for line in f:
            label, text = line.strip().split(' ||| ')
            x_data.append(text)
            y_data.append(int(label))
    return x_data, y_data

x_train, y_train = read_xy_data('../data/sst-sentiment-text-threeclass/train.txt')
x_test, y_test = read_xy_data('../data/sst-sentiment-text-threeclass/dev.txt')

print(x_train[0])
print(y_train[0])

"""## Run the Classifier and Calculate Accuracy

Run the classifier over the training and dev (test) sets and calculate accuracy
"""

def run_classifier(x: str) -> int:
    score = 0
    for feat_name, feat_value in extract_features(x).items():
        score = score + feat_value * feature_weights.get(feat_name, 0)
    if score > 0:
        return 1
    elif score < 0:
        return -1
    else:
        return 0

def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:
    total_number = 0
    correct_number = 0
    for x, y in zip(x_data, y_data):
        y_pred = run_classifier(x)
        total_number += 1
        if y == y_pred:
            correct_number += 1
    return correct_number / float(total_number)

label_count = {}
for y in y_test:
    if y not in label_count:
        label_count[y] = 0
    label_count[y] += 1
print(label_count)

train_accuracy = calculate_accuracy(x_train, y_train)
test_accuracy = calculate_accuracy(x_test, y_test)
print(f'Train accuracy: {train_accuracy}')
print(f'Dev/test accuracy: {test_accuracy}')

"""## Error Analysis è¯¯å·®åˆ†æ

æ”¹è¿›ä»»ä½•ç³»ç»Ÿçš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†å°±æ˜¯æ‰¾å‡ºé—®é¢˜å‡ºåœ¨å“ªé‡Œã€‚ä¸‹é¢è¿™ä¸ªå‡½æ•°å…è®¸æ‚¨éšæœºè§‚å¯Ÿä¸€äº›é”™è¯¯çš„ç¤ºä¾‹ï¼Œè¿™å¯èƒ½æœ‰åŠ©äºæ‚¨æ”¹è¿›åˆ†ç±»å™¨ã€‚æ‚¨ä¹Ÿå¯ä»¥ä¸ºé”™è¯¯åˆ†æç¼–å†™æ›´å¤æ‚çš„æ–¹æ³•ã€‚
"""

import random
def find_errors(x_data, y_data):
    error_ids = []
    y_preds = []
    for i, (x, y) in enumerate(zip(x_data, y_data)):
        y_preds.append(run_classifier(x))
        if y != y_preds[-1]:
            error_ids.append(i)
    for _ in range(5):
        my_id = random.choice(error_ids)
        x, y, y_pred = x_data[my_id], y_data[my_id], y_preds[my_id]
        print(f'{x}\ntrue label: {y}\npredicted label: {y_pred}\n')

find_errors(x_train, y_train)