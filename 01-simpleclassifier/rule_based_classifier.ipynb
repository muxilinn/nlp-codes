{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ„å»ºåŸºäºè§„åˆ™çš„æƒ…æ„Ÿåˆ†ç±»å™¨\n",
    "\n",
    "è¿™æ˜¯[æ·±åœ³æŠ€æœ¯å¤§å­¦2025ç§‹å­£å¾®ä¸“ä¸šè¯¾](https://hqyang.github.io/nlp-fall25/)ä½¿ç”¨çš„Jupyter Notebook.ä¸‹é¢å°è¯•æ„å»ºåŸºä¸€ä¸ªåŸºäºè§„åˆ™çš„æƒ…æ„Ÿåˆ†ç±»å™¨ã€‚å®ƒå°†æ¥æ”¶æ–‡æœ¬â€œXâ€å¹¶è¿”å›ä¸€ä¸ªâ€œæ ‡ç­¾â€ï¼Œå¦‚æœæ–‡æœ¬çš„æƒ…æ„Ÿæ˜¯ç§¯æçš„ï¼Œåˆ™ä¸ºâ€œ1â€ï¼Œå¦‚æœæ–‡æœ¬çš„æƒ…æ„Ÿæ˜¯æ¶ˆæçš„ï¼Œåˆ™ä¸ºâ€œ-1â€ï¼Œå¦‚æœæ–‡æœ¬çš„æƒ…æ„Ÿæ˜¯ä¸­æ€§çš„ï¼Œåˆ™ä¸ºâ€œ0â€ã€‚é€šè¿‡è¿è¡Œè¿™ä¸ªnotebook ä½ å¯ä»¥åœ¨[Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/index.html)ä¸Šæµ‹è¯•åˆ†ç±»å™¨çš„å‡†ç¡®æ€§ã€‚\n",
    "\n",
    "Notebookå”¯ä¸€éœ€è¦æ›´æ”¹çš„æ˜¯ä»¥ä¸‹ä¸¤ä¸ªå•å…ƒæ ¼: \n",
    "1. `extract_features(X)`: å®ƒå°†ä»æ–‡æœ¬ä¸­æå–ï¼ˆå‘½åçš„ï¼‰ç‰¹å¾å€¼çš„å­—å…¸ã€‚æ‚¨åº”è¯¥è‡ªå·±æ‰‹åŠ¨åˆ›å»ºå­—å…¸ï¼Œä¸‹é¢å°†ä¸ºæ‚¨å±•ç¤ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ã€‚\n",
    "2. `feature_weights`: è¿™æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå®ƒå°†ä¸ºæ¯ä¸ªæå–çš„ç‰¹å¾åˆ†é…ä¸€ä¸ªæƒé‡ã€‚\n",
    "\n",
    "åˆ†ç±»å™¨å†³å®šæ˜¯å¦åˆ†é…ç§¯æã€æ¶ˆææˆ–ä¸­æ€§æ ‡ç­¾çš„æœ€ç»ˆæ–¹æ³•æ˜¯é€šè¿‡è®¡ç®—ç‚¹ç§¯`feature_weights * extract_features(X)`ï¼Œå¦‚æœå€¼å¤§äºé›¶ï¼Œè¿”å›1ï¼Œå°äºé›¶è¿”å›-1ï¼Œå¦‚æœæ­£å¥½ä¸ºé›¶è¿”å›0ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬æ¥å°è¯•è®¾è®¡ä¸€ä¸ªåˆ†ç±»å™¨ ğŸ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x: str) -> dict[str, float]:\n",
    "    features = {}\n",
    "    x_split = x.split(' ')\n",
    "    \n",
    "    # Count the number of \"good words\" and \"bad words\" in the text\n",
    "    good_words = ['love', 'good', 'nice', 'great', 'enjoy', 'enjoyed']\n",
    "    bad_words = ['hate', 'bad', 'terrible', 'disappointing', 'sad', 'lost', 'angry']\n",
    "    for x_word in x_split:\n",
    "        if x_word in good_words:\n",
    "            features['good_word_count'] = features.get('good_word_count', 0) + 1\n",
    "        if x_word in bad_words:\n",
    "            features['bad_word_count'] = features.get('bad_word_count', 0) + 1\n",
    "    \n",
    "    # The \"bias\" value is always one, to allow us to assign a \"default\" score to the text\n",
    "    features['bias'] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "feature_weights = {'good_word_count': 1.0, 'bad_word_count': -1.0, 'bias': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading\n",
    "\n",
    "Read in the data from the training and dev (or finally test) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ')\n",
    "            x_data.append(text)\n",
    "            y_data.append(int(label))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_xy_data('../data/sst-sentiment-text-threeclass/train.txt')\n",
    "x_test, y_test = read_xy_data('../data/sst-sentiment-text-threeclass/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Classifier and Calculate Accuracy\n",
    "\n",
    "Run the classifier over the training and dev (test) sets and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(x: str) -> int:\n",
    "    score = 0\n",
    "    for feat_name, feat_value in extract_features(x).items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:\n",
    "    total_number = 0\n",
    "    correct_number = 0\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        y_pred = run_classifier(x)\n",
    "        total_number += 1\n",
    "        if y == y_pred:\n",
    "            correct_number += 1\n",
    "    return correct_number / float(total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 444, 0: 229, -1: 428}\n"
     ]
    }
   ],
   "source": [
    "label_count = {}\n",
    "for y in y_test:\n",
    "    if y not in label_count:\n",
    "        label_count[y] = 0\n",
    "    label_count[y] += 1\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4345739700374532\n",
      "Dev/test accuracy: 0.4214350590372389\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(x_train, y_train)\n",
    "test_accuracy = calculate_accuracy(x_test, y_test)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis è¯¯å·®åˆ†æ\n",
    "\n",
    "æ”¹è¿›ä»»ä½•ç³»ç»Ÿçš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†å°±æ˜¯æ‰¾å‡ºé—®é¢˜å‡ºåœ¨å“ªé‡Œã€‚ä¸‹é¢è¿™ä¸ªå‡½æ•°å…è®¸æ‚¨éšæœºè§‚å¯Ÿä¸€äº›é”™è¯¯çš„ç¤ºä¾‹ï¼Œè¿™å¯èƒ½æœ‰åŠ©äºæ‚¨æ”¹è¿›åˆ†ç±»å™¨ã€‚æ‚¨ä¹Ÿå¯ä»¥ä¸ºé”™è¯¯åˆ†æç¼–å†™æ›´å¤æ‚çš„æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def find_errors(x_data, y_data):\n",
    "    error_ids = []\n",
    "    y_preds = []\n",
    "    for i, (x, y) in enumerate(zip(x_data, y_data)):\n",
    "        y_preds.append(run_classifier(x))\n",
    "        if y != y_preds[-1]:\n",
    "            error_ids.append(i)\n",
    "    for _ in range(5):\n",
    "        my_id = random.choice(error_ids)\n",
    "        x, y, y_pred = x_data[my_id], y_data[my_id], y_preds[my_id]\n",
    "        print(f'{x}\\ntrue label: {y}\\npredicted label: {y_pred}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most folks with a real stake in the American sexual landscape will find it either moderately amusing or just plain irrelevant .\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "\n",
      "An annoying orgy of excess and exploitation that has no point and goes nowhere .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n",
      "Possibly not since Grumpy Old Men have I heard a film so solidly connect with one demographic while striking out with another .\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "\n",
      "It 's better than mid-range Steven Seagal , but not as sharp as Jet Li on rollerblades .\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "\n",
      "` Hey Arnold ! '\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_errors(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
